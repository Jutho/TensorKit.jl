<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Introduction · TensorKit.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>TensorKit.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><span class="toctext">Manual</span><ul><li class="current"><a class="toctext" href>Introduction</a><ul class="internal"><li><a class="toctext" href="#ss_tensor-1">What is a tensor?</a></li><li><a class="toctext" href="#ss_symmetries-1">Symmetries and block sparsity</a></li><li><a class="toctext" href="#ss_category-1">Monoidal categories and their properties (optional)</a></li><li><a class="toctext" href="#Bibliography-1">Bibliography</a></li></ul></li><li><a class="toctext" href="../spaces/">Vector spaces</a></li><li><a class="toctext" href="../sectors/">Sectors, representation spaces and fusion trees</a></li><li><a class="toctext" href="../tensors/">Tensors and the <code>TensorMap</code> type</a></li></ul></li><li><span class="toctext">Library</span><ul><li><a class="toctext" href="../../lib/spaces/">Vector spaces</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Manual</li><li><a href>Introduction</a></li></ul><a class="edit-page" href="https://github.com/Jutho/TensorKit.jl/blob/master/docs/src/man/intro.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Introduction</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="s_intro-1" href="#s_intro-1">Introduction</a></h1><p>Before providing a typical &quot;user guide&quot; and discussing the implementation of TensorKit.jl on the next pages, let us discuss some of the rationale behind this package.</p><h2><a class="nav-anchor" id="ss_tensor-1" href="#ss_tensor-1">What is a tensor?</a></h2><p>At the very start we should ponder about the most suitable and sufficiently general definition of a tensor. A good starting point is the following:</p><ul><li><p>A tensor <span>$t$</span> is an element from the   <a href="https://en.wikipedia.org/wiki/Tensor_product">tensor product</a> of <span>$N$</span> vector spaces   <span>$V_1 , V_2, …, V_N$</span>, where <span>$N$</span> is referred to as the <em>rank</em> or <em>order</em> of the   tensor, i.e.</p><p><span>$t ∈ V_1 ⊗ V_2 ⊗ … ⊗ V_N.$</span></p></li></ul><p>If you think of a tensor as an object with indices, a rank <code>N</code> tensor has <code>N</code> indices where every index is associated with the corresponding vector space in that it labels a particular basis in that space. We will return to index notation at the very end of this manual.</p><p>As the tensor product of vector spaces is itself a vector space, this implies that a tensor behaves as a vector, i.e. tensors from the same tensor product space can be added and multiplied by scalars. The tensor product is only defined for vector spaces over the same field, i.e. there is no meaning in <span>$ℝ^5 ⊗ ℂ^3$</span>. When all the vector spaces in the tensor product have an inner product, this also implies an inner product for the tensor product space. It is hence clear that the different vector spaces in the tensor product should have some form of homogeneity in their structure, yet they do not need to be all equal and can e.g. have different dimensions. It goes without saying that defining the vector spaces and their properties will be an important part of the definition of a tensor. As a consequence, this also constitutes a significant part of the implementation, and is discussed in the section on <a href="man/@ref">Vector spaces</a>.</p><p>Aside from the interpretation of a tensor as a vector, we also want to interpret it as a matrix (or more correctly, a linear map) in order to decompose tensors using linear algebra factorisations (e.g. eigenvalue or singular value decomposition). Henceforth, we use the term &quot;tensor map&quot; as follows:</p><ul><li><p>A tensor map <span>$t$</span> is a linear map from a source or <em>domain</em>   <span>$W_1 ⊗ W_2 ⊗ … ⊗ W_{N_2}$</span> to a target or <em>codomain</em> <span>$V_1 ⊗ V_2 ⊗ … ⊗ V_{N_1}$</span>, i.e.</p><p><span>$t:W_1 ⊗ W_2 ⊗ … ⊗ W_{N_2} → V_1 ⊗ V_2 ⊗ … ⊗ V_{N_1}.$</span></p></li></ul><p>A <em>tensor</em> of rank <code>N</code> is then just a special case of a tensor map with <span>$N_1 = N$</span> and <span>$N_2 = 0$</span>. A contraction between two tensors is just a composition of linear maps (i.e. matrix multiplication), where the contracted indices correspond to the domain of the first tensor and the codomain of the second tensor.</p><p>In order to allow for arbitrary tensor contractions or decompositions, we need to be able to reorganise which vector spaces appear in the domain and the codomain of the tensor map, and in which order. This amounts to defining canonical isomorphisms between the different ways to order and partition the tensor indices (i.e. the vector spaces). For example, a linear map <span>$W → V$</span> is often denoted as a rank 2 tensor in <span>$V ⊗ W^*$</span>, where <span>$W^*$</span> corresponds to the dual space of <code>W</code>. This simple example introduces two new concepts.</p><ol><li><p>Typical vector spaces can appear in the domain and codomain in different variants, e.g.  as normal space or dual space. In fact, the most generic case is that every vector  space <span>$V$</span> has associated with it  a <a href="https://en.wikipedia.org/wiki/Dual_space">dual space</a> <span>$V^*$</span>,  a <a href="https://en.wikipedia.org/wiki/Complex_conjugate_vector_space">conjugate space</a>  <span>$\overline{V}$</span> and a conjugate dual space <span>$\overline{V}^*$</span>. The four different  vector spaces <span>$V$</span>, <span>$V^*$</span>, <span>$\overline{V}$</span> and <span>$\overline{V}^*$</span> correspond to the  representation spaces of respectively the fundamental, dual or contragredient, complex  conjugate and dual complex conjugate representation of the general linear group  <span>$\mathsf{GL}(V)$</span> <a href="#footnote-tung">[tung]</a>. In index notation these spaces are denoted with  respectively contravariant (upper), covariant (lower), dotted contravariant  and dotted covariant indices.</p><p>For real vector spaces, the conjugate (dual) space is identical to the normal (dual)  space and we only have upper and lower indices, i.e. this is the setting of e.g.  general relativity. For (complex) vector spaces with a sesquilinear inner product  <span>$\overline{V} ⊗ V → ℂ$</span>, the inner product allows to define an isomorphism from the  conjugate space to the dual space (known as  <a href="https://en.wikipedia.org/wiki/Riesz_representation_theorem">Riesz representation theorem</a>  in the more general context of Hilbert spaces).</p><p>In particular, in spaces with a Euclidean inner product (the setting of e.g. quantum  mechanics), the conjugate and dual space are naturally isomorphic (because the dual and  conjugate representation of the unitary group are the same). Again we only need upper  and lower indices (or kets and bras).</p><p>Finally, in <span>$ℝ^d$</span> with a Euclidean inner product, these four different spaces are  equivalent and we only need one type of index. The space is completely characterized by  its dimension <code>d</code>. This is the setting of much of classical mechanics and we refer to  such tensors as cartesian tensors and the corresponding space as cartesian space. These  are the tensors that can equally well be represented as multidimensional arrays (i.e.  using some <code>AbstractArray{&lt;:Real,N}</code> in Julia) without loss of structure.</p><p>The implementation of all of this is discussed in <a href="man/@ref">Vector spaces</a>.</p></li><li><p>In the generic case, the identification between maps <span>$W → V$</span> and tensors in  <span>$V ⊗ W^*$</span> is not an equivalence but an isomorphism, which needs to be defined.  Similarly, there is an isomorphism between between <span>$V ⊗ W$</span> and <span>$W ⊗ V$</span> that can be  non-trivial (e.g. in the case of fermions / super vector spaces). The correct formalism  here is provided by theory of monoidal categories. Nonetheless, we try to hide these  canonical isomorphisms from the user wherever possible.</p></li></ol><p>This brings us to our final (yet formal) definition</p><ul><li>A tensor (map) is a homorphism between two objects from the category <span>$\mathbf{Vect}$</span>   (or some subcategory thereof). In practice, this will be <span>$\mathbf{FinVect}$</span>, the   category of finite dimensional vector spaces. More generally, our concept of a tensor   makes sense, in principle, for any <span>$\mathbf{Vect}$</span>-enriched monoidal category. We refer to the section &quot;<a href="man/@ref">Monoidal categories and their properties (optional)</a>&quot;.</li></ul><h2><a class="nav-anchor" id="ss_symmetries-1" href="#ss_symmetries-1">Symmetries and block sparsity</a></h2><p>Physical problems often have some symmetry, i.e. the setup is invariant under the action of a group <span>$\mathsf{G}$</span> which acts on the vector spaces <span>$V$</span> in the problem according to a certain representation. Having quantum mechanics in mind, TensorKit.jl restricts so far to unitary representations. A general representation space <span>$V$</span> can be specified as the number of times every irreducible representation (irrep) <code>a</code> of <span>$\mathsf{G}$</span> appears, i.e.</p><p><span>$V = \bigoplus_{a} ℂ^{n_a} ⊗ R_a$</span></p><p>with <span>$R_a$</span> the space associated with irrep <span>$a$</span> of <span>$\mathsf{G}$</span>, which itself has dimension <span>$d_a$</span> (often called the quantum dimension), and <span>$n_a$</span> the number of times this irrep appears in <span>$V$</span>. If the unitary irrep <span>$a$</span> for <span>$g ∈ \mathsf{G}$</span> is given by <span>$u_a(g)$</span>, then the group action of <span>$\mathsf{G}$</span> on <span>$V$</span> is given by the unitary representation</p><p><span>$u(g) = \bigoplus_{a}  𝟙_{n_a} ⊗ u_a(g)$</span></p><p>with <span>$𝟙_{n_a}$</span> the <span>$n_a × n_a$</span> identity matrix. The total dimension of <span>$V$</span> is given by <span>$∑_a n_a d_a$</span>.</p><p>The reason of implementing symmetries is to exploit the compuation and memory gains resulting from restricting to tensor maps <span>$t:W_1 ⊗ W_2 ⊗ … ⊗ W_{N_2} → V_1 ⊗ V_2 ⊗ … ⊗ V_{N_1}$</span> that are invariant under the symmetry (i.e. that act as <a href="https://en.wikipedia.org/wiki/Equivariant_map#Representation_theory">intertwiners</a> between the symmetry action on the domain and the codomain). Indeed, such tensors should be block diagonal because of <a href="https://en.wikipedia.org/wiki/Schur%27s_lemma">Schur&#39;s lemma</a>, but only after we couple the individual irreps in the spaces <span>$W_i$</span> to a joint irrep, which is then again split into the individual irreps of the spaces <span>$V_i$</span>. The basis change from the tensor product of irreps in the (co)domain to the joint irrep isimplemented by a sequence of Clebsch-Gordan coefficients, also known as a fusion (or splitting) tree. We implement the necessary machinery to manipulate these fusion trees under index permutations and repartitions for arbitrary groups <span>$\mathsf{G}$</span>. In particular, this fits with the formalism of monoidal categories, and more specifically fusion categoreis, discussed below and only requires the <em>topological</em> data of the group, i.e. the fusion rules of the irreps, their quantum dimensions and the F-symbol (6j-symbol or more precisely Racah&#39;s W-symbol in the case of <span>$\mathsf{SU}_2$</span>). In particular, we do not need the Clebsch-Gordan coefficients.</p><p>Further details are provided in <a href="man/@ref">Sectors, representation spaces and fusion trees</a>.</p><h2><a class="nav-anchor" id="ss_category-1" href="#ss_category-1">Monoidal categories and their properties (optional)</a></h2><p>The purpose of this final introductory section (which can safely be skipped), is to explain how certain concepts and terminology from the theory of monoidal categories apply in the context of tensors.  In the end, identifying tensor manipulations in TensorKit.jl with concepts from category theory is to put the diagrammatic formulation of tensor networks in the most general context on a firmer footing. The following definitions are mostly based on <a href="#footnote-selinger">[selinger]</a>, <a href="#footnote-kassel">[kassel]</a> and <a href="https://ncatlab.org/"><span>$n$</span>Lab</a>, to which we refer for further information. Furthermore, we recommend the nice introduction of <a href="man/^beer">Beer et al.</a></p><p>To start, a category <span>$C$</span> consists of</p><ul><li>a class <span>$|C|$</span> of objects <span>$V$</span>, <span>$W$</span>, …</li><li>for each pair of objects <span>$V$</span> and <span>$W$</span>, a set <span>$hom(W,V)$</span> of morphisms <span>$f:W→V$</span>;   for a given map <code>f</code>, <code>W</code> is called the <em>domain</em> or <em>source</em>, and <code>V</code> the <em>codomain</em> or   <em>target</em>.</li><li>an composition of morphisms <span>$f:W→V$</span> and <span>$g:X→W$</span> into <span>$(f ∘ g):X→V$</span> that is   associative, such that for <span>$h:Y→X$</span> we have <span>$f ∘ (g ∘ h) = (f ∘ g) ∘ h$</span></li><li>for each object <span>$V$</span>, an identity morphism <span>$\mathrm{id}_V:V→V$</span> such that   <span>$f ∘ \mathrm{id}_W = f = \mathrm{id}_V ∘ f$</span>.</li></ul><p>In our case, i.e. the category <span>$\mathbf{Vect}$</span> (or some subcategory thereof), the objects are vector spaces, and the morphisms are linear maps between these vector spaces with &quot;matrix multiplication&quot; as composition. We refer to these morphisms as tensor maps exactly because there is a binary operation <code>⊗</code>, the tensor product, that allows to combine objects into new objects. This makes <span>$\mathbf{Vect}$</span> into a <strong>tensor category</strong>, a.k.a a <em>monoidal category</em>, which has</p><ul><li>a binary operation on objects <span>$⊗: |C| × |C| → |C|$</span></li><li>a binary operation on morphisms, also denoted as <span>$⊗$</span>, such that   <span>$⊗: hom(W_1,V_1) × hom(W_2,V_2) → hom(W_1 ⊗ W_2, V_1 ⊗ V_2)$</span></li><li>an identity object <span>$I$</span></li><li>three families of natural isomorphisms:<ul><li><span>$∀ V ∈ |C|$</span>, a left unitor <span>$λ_V: I ⊗ V → V$</span></li><li><span>$∀ V ∈ |C|$</span>, a right unitor <span>$ρ_V: V ⊗ I → V$</span></li><li><span>$∀ V_1, V_2, V_3 ∈ |C|$</span>, an associator   <span>$α_{V_1,V_2,V_3}:(V_1 ⊗ V_2) ⊗ V_3 → V_1 ⊗ (V_2 ⊗ V_3)$</span></li></ul>that satisfy certain consistency conditions (coherence axioms), which are known as the   <em>triangle equation</em> and <em>pentagon equation</em>.</li></ul><p>In abstract terms, <span>$⊗$</span> is a (bi)functor from the product category <span>$C × C$</span> to <span>$C$</span>.</p><p>For the category <span>$\mathbf{Vect}$</span>, the identity object <span>$I$</span> is just the scalar field, which can be identified with a one-dimensional vector space. Every monoidal category is equivalent to a strict tensor category, where the left and right unitor and associator act as the identity and their domain and codomain are truly identical. Nonetheless, for tensor maps, we do actually discriminate between <span>$V$</span>, <span>$I ⊗ V$</span> and <span>$V ⊗ I$</span> because this amounts to adding or removing an extra factor <code>I</code> to the tensor product structure of the (co)domain, i.e. the left and right unitor are analogous to removing extra dimensions of size 1 from an array, and an actual operation is required to do so (this has in fact led to some controversy in several programming languages that provide native support for multidimensional arrays). For what concerns the associator, the distinction between <span>$(V_1 ⊗ V_2) ⊗ V_3$</span> and <span>$V_1 ⊗ (V_2 ⊗ V_3)$</span> is typically absent for simple tensors or multidimensional arrays. However, this grouping can be taken to indicate how to build the fusion tree for coupling irreps to a joint irrep in the case of symmetric tensors. As such, going from one to the other requires a recoupling (F-move) which has a non-trivial action on the reduced blocks. We return to this in <a href="../sectors/#s_sectorsrepfusion-1">the section on fusion trees</a>. However, we can already note that we will always represent tensor products using a canonical order <span>$(…((V_1 ⊗ V_2) ⊗ V_3) … ⊗ V_N)$</span>. A similar approach can be followed to map any tensor category into a strict tensor category (see Section XI.5 of <a href="#footnote-kassel">[kassel]</a>).</p><p>With these definitions, we have the minimal requirements for defining tensor maps. In principle, we could use a more general definition and define tensor maps as morphism of any tensor category where the hom-sets are themselves vector spaces, such that we can add morphisms and multiply them with scalars. Such categories are called <span>$\mathbf{Vect}$</span>-enriched.</p><p>In order to make tensor (maps) useful and to define operations with them, we can now introduce additional structure or quantifiers to the tensor category for which they are the morphisms.</p><h3><a class="nav-anchor" id="sss_braiding-1" href="#sss_braiding-1">Braiding</a></h3><p>To reorder tensor indices, or, equivalently, to reorder objects in the tensor product <span>$V_1 ⊗ V_2 ⁠⊗ … V_N$</span>, we need at the very least a <strong>braided tensor category</strong> which has, <span>$∀ V, W ∈ |C|$</span>, a braiding <span>$σ_{V,W}: V⊗W → W⊗V$</span>. A valid braiding needs to satisfy consistency condition with the associator <span>$α$</span> known as the <em>hexagon equation</em>.</p><p>However, for general braidings, there is no unique choice to identify a tensor in <span>$V⊗W$</span> and <span>$W⊗V$</span>, as any of the maps <span>$σ_{V,W}$</span>, <span>$σ_{W,V}^{-1}$</span>, <span>$σ_{V,W} ∘ σ_{W,V} ∘ σ_{V,W}$</span>, …  mapping from <span>$V⊗W$</span> to <span>$W⊗V$</span> are all different. In order for there to be a unique map from <span>$V_1 ⊗ V_2 ⁠⊗ … V_N$</span> to any permutation of the objects in this tensor product, the braiding needs to be <em>symmetric</em>, i.e. <span>$σ_{V,W} = σ_{W,V}^{-1}$</span> or, equivalently <span>$σ_{W,V} ∘ σ_{V,W} = \mathrm{id}_{V⊗W}$</span>. The resulting category is then referred to as a <strong>symmetric tensor category</strong>. In a graphical representation, it means that there is no distinction between over- and under- crossings and, as such, lines can just cross.</p><p>For a simple cartesian tensor, permuting the tensor indices is equivalent to applying Julia&#39;s function <code>permutedims</code> on the underlying data. Less trivial braiding implementations arise in the context of tensors with symmetries (where the fusion tree needs to be reordered) or in the case of fermions (described using so-called super vector spaces where the braiding is given by the Koszul sign rule).</p><h3><a class="nav-anchor" id="sss_dual-1" href="#sss_dual-1">Duals</a></h3><p>For tensor maps, the braiding structure only allows to reorder the objects within the domain or within the codomain separately. An <strong>autonomous</strong> or <strong>rigid</strong> monoidal category is one where objects have duals, defined via an exact pairing, i.e. two families of canonical maps, the unit <span>$η_V: I → V ⊗ V^*$</span> and the co-unit <span>$ϵ_V: V^* ⊗ V → I$</span> that satisfy the &quot;snake rules&quot;</p><p><span>$ρ_V ∘ (\mathrm{id}_V ⊗ ϵ_V) ∘ (η_V ⊗ \mathrm{id}_V) ∘ λ_V^{-1} = \mathrm{id}_V$</span></p><p><span>$λ_{V^*}^{-1} ∘ (ϵ_V ⊗ \mathrm{id}_{V^*}) ∘ (\mathrm{id}_{V^*} ⊗ η_V) ∘ ρ_{V^*}^{-1} = \mathrm{id}_{V^*}$</span></p><p>Given a morphism <span>$t::W→V$</span>, we can now identify it with <span>$(t ⊗ \mathrm{id}_{W^*}) ∘ η_W$</span> to obtain a morphism <span>$I→V⊗W^*$</span>. For the category <span>$\mathbf{Vect}$</span>, this is the identification between linear maps <span>$W→V$</span> and tensors in <span>$V⊗W^*$</span>. In particular, for complex vector spaces, using a bra-ket notation and a generic basis <span>${|n⟩}$</span> for <span>$V$</span> and dual basis <span>${⟨m|}$</span> for <span>$V^*$</span> (such that <span>$⟨m|n⟩ = δ_{m,n}$</span>), the unit is <span>$η_V:ℂ → V ⊗ V^*:λ → λ ∑_n |n⟩ ⊗ ⟨n|$</span> and the co-unit is <span>$⁠ϵ_V:V^* ⊗ V → ℂ: ⟨m| ⊗ |n⟩ → δ_{m,n}$</span>. Note that this does not require an inner product, i.e. no mapping from <span>$|n⟩$</span> to <span>$⟨n|$</span> was defined.</p><p>For a general tensor map <span>$t:W_1 ⊗ W_2 ⊗ … ⊗ W_{N_2} → V_1 ⊗ V_2 ⊗ … ⊗ V_{N_1}$</span>, by successively applying <span>$η_{W_{N_2}}$</span>, <span>$η_{W_{N_2-1}}$</span>, …, <span>$η_{W_{1}}$</span> (and the left or right unitor) but no braiding, we obtain a tensor in <span>$V_1 ⊗ V_2 ⊗ … ⊗ V_{N_1} ⊗ W_{N_2}^* ⊗ … ⊗ W_{1}^*$</span>. It does makes sense to define or identify <span>$(W_1 ⊗ W_2 ⊗ … ⊗ W_{N_2})^* = W_{N_2}^* ⊗ … ⊗ W_{1}^*$</span>.</p><p>In fact, the above exact pairings are known as the left unit and co-unit, and <span>$V^*$</span> is the left dual of <span>$V$</span>. There is also a notion of a right dual <span>$^*V$</span> and associated pairings, the right unit <span>$η&#39;_V: I → ^*V ⊗ V$</span> and the right co-unit <span>$ϵ&#39;_V: V ⊗ *^V → I$</span>. An autonomous category <code>\mathbf{C}</code> is one where every object <code>V</code> has both a left and right dual, and in this case they can be proven to be isomorphic. We will never distinguish between the two and refer simply to <code>dual(V)</code> for the dual of a vector space.</p><p>The braiding of a space and a dual space also follows naturally, it is given by <span>$σ_{V^*,W} = λ_{W ⊗ V^*} ∘ (ϵ_V ⊗ \mathrm{id}_{W ⊗ V^*}) ∘ (\mathrm{id}_{V^*} ⊗ σ_{V,W}^{-1} ⊗ \mathrm{id}_{V^*}) ∘ (\mathrm{id}_{V^*⊗ W} ⊗ η_V) ∘ ρ_{V^* ⊗ W}^{-1}$</span></p><p>In general categories, one can distinguish between a left and right dual, but we always assume that both objects are naturally isomorphic. Equivalently, <span>$V^{**} ≂ V$</span> and the category is said to be  <strong>pivotal</strong>. For every morphism <span>$f:W→V$</span>, there is then a well defined notion of a transpose (also called adjoint mate) <span>$f^*:V^* → W^*$</span> as</p><p><span>$f^* = λ_{W^*} ∘ (ϵ_V ⊗ \mathrm{id}_{W^*}) ∘ (\mathrm{id}_{V^*} ⊗ f ⊗ \mathrm{id}_{W^*}) ∘ (\mathrm{id}_{V^*} ⊗ η_{W}) ∘ ρ_{V^*}^{-1}$</span></p><p><span>$f^* = ρ_{W^*} ∘ (\mathrm{id}_{W^*} ⊗ ϵ_{V^*}) ∘ (\mathrm{id}_{V^*} ⊗ f ⊗ \mathrm{id}_{W^*}) ∘ (η_{W^*} ⊗ \mathrm{id}_{V^*}) ∘ λ_{V^*}^{-1}$</span></p><p>and both definitions coincide (which is not the case if the category is not pivotal). In a graphical representation, this means that boxes (representing tensor maps or morphisms more generally) can be rotated. The transpose corresponds to a 180˚ rotation (either way).</p><p>A braiding <span>$σ_{V,V^*}$</span> provides a particular way to construct an maps <span>$ϵ_{V^*} = ϵ_V ∘ σ_{V,V^*} : V⊗V^* → I$</span> and <span>$η_{V^*} = σ_{V^*,V}^{-1} \circ η_V: I→ V^*⊗V$</span>, but these maps are not canonical for general braidings, so that a braided autonomous category is not automatically pivotal. A category that is both braided and pivotal automatically has a twist (and is thus balanced), vice versa a balanced autonomous category is automatically pivotal. However, the graphical representation using ribbons is only consistent if we furthermore have <span>$θ_{V^*} = θ_V^*$</span> (i.e. the transpose), in which case the category is said to be <strong>tortile</strong> or also a <strong>ribbon category</strong>.</p><p>In the case of a symmetric braiding, most of these difficulties go away and the pivotal structure follows. A symmetric monoidal category with duals is known as a <strong>compact closed category</strong>.</p><p>We can extend a braided category with a <strong>twist</strong> <span>$θ_V$</span>, i.e. a family of isomorphisms <span>$θ_V:V→V$</span> that satisfy <span>$θ_{V⊗W} = σ_{W,V} ∘ (θ_W ⊗ θ_V) ∘ σ_{V,W}$</span> and the resulting category is called a <strong>balanced</strong> monoidal category. The corresponding graphical representation is that where objects are denoted by ribbons instead of lines, and a twist is consistent with the graphical representation of a twisted ribbon and how it combines with braidings.</p><h3><a class="nav-anchor" id="sss_adjoints-1" href="#sss_adjoints-1">Adjoints</a></h3><h2><a class="nav-anchor" id="Bibliography-1" href="#Bibliography-1">Bibliography</a></h2><div class="footnote" id="footnote-tung"><a href="#footnote-tung"><strong>[tung]</strong></a><pre><code class="language-none">    Tung, W. K. (1985). Group theory in physics: an introduction to symmetry
        principles, group representations, and special functions in classical and
        quantum physics.
        World Scientific Publishing Company.</code></pre></div><div class="footnote" id="footnote-selinger"><a href="#footnote-selinger"><strong>[selinger]</strong></a><pre><code class="language-none">Selinger, P. (2010). A survey of graphical languages for monoidal
        categories.
        In New structures for physics (pp. 289-355). Springer, Berlin, Heidelberg.</code></pre></div><div class="footnote" id="footnote-beer"><a href="#footnote-beer"><strong>[beer]</strong></a><pre><code class="language-none">    From categories to anyons: a travelogue
        Kerstin Beer, Dmytro Bondarenko, Alexander Hahn, Maria Kalabakov, Nicole
        Knust, Laura Niermann, Tobias J. Osborne, Christin Schridde, Stefan
        Seckmeyer, Deniz E. Stiege- mann, and Ramona Wolf
        [https://arxiv.org/pdf/1811.06670.pdf](https://arxiv.org/pdf/1811.06670.pdf)</code></pre></div><footer><hr/><a class="previous" href="../../"><span class="direction">Previous</span><span class="title">Home</span></a><a class="next" href="../spaces/"><span class="direction">Next</span><span class="title">Vector spaces</span></a></footer></article></body></html>
